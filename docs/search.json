[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adam Coates",
    "section": "",
    "text": "About\n\nHello, I’m Adam a PhD student in Cognitive Psychology at the University of Graz, Austria.\n\n\n:::"
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html",
    "href": "posts/2023-04-01-30DCC-01/index.html",
    "title": "30-DCC day 1",
    "section": "",
    "text": "I am intrigued by the #30DaysChartChallenge that started today. It’s a “…community-driven event with the goal to create a data visualization on a certain topic each day of April”. Each day you’re provided a prompt and using any tools you develop a data visualization.\nI think this would be a great way to learn some new R tidyverse and tidymodelling skills so thought I’d give it a try. I am not sure how many days I will be able to keep it up, but day one was fun."
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html#overview",
    "href": "posts/2023-04-01-30DCC-01/index.html#overview",
    "title": "30-DCC day 1",
    "section": "Overview",
    "text": "Overview\nToday’s prompt was “part-to-whole”. I will be honest, I didn’t know what was meant by a “part-to-whole” data visualisation, so I did what all the cool kids are doing these days and I asked Chat-GPT:\n\n\n\n\n\nOK, that’s a little clearer. What is more clear is that I am not going to do a pie chart! But first I need some data."
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html#ultrarunning-eating",
    "href": "posts/2023-04-01-30DCC-01/index.html#ultrarunning-eating",
    "title": "30-DCC day 1",
    "section": "Ultrarunning & Eating",
    "text": "Ultrarunning & Eating\nSince the UK lockdown in March 2020 I’ve caught the running bug. Last year, I completed my first marathon, and I have signed up to two marathons this year. The marathon is—obviously—a tough distance; but some (crazy) people run Ultra-marathons which is any race longer than the 26.2 miles of a standard marathon.\nIf you’re training for an ultra-marathon, you probably want to make sure your diet during your training is good to ensure you are getting the necessary nutrients and energy. It’s not untypical for ultra-runners to consume anywhere between 3,000 to 6,000 calories a day during training. As for macro-nutrient recommendations, the guidelines for ultra-runners are not very different from those for other endurance athletes. The general recommendation for endurance athletes is as follows:\n\nCarbohydrates: 45-65% of total daily calories.\nProtein: 15-20% of total daily calories.\nFats: 20-35% of total daily calories.\n\nLet’s say you’re interested in making a daily log of your total daily calorie intake together with tracking your macro-nutrients. For each day, how did each of the macro-nutrients (i.e., the part) contribute to total calorie intake (i.e., the whole)?"
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html#simulating-the-data",
    "href": "posts/2023-04-01-30DCC-01/index.html#simulating-the-data",
    "title": "30-DCC day 1",
    "section": "Simulating the data",
    "text": "Simulating the data\nFirst let’s load the required packages and do a general set-up:\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\ntheme_set(theme_bw())\n\nLet’s simulate data for the month of April 2023. For each day, we log/generate the following data:\n\ndate: Date of the daily log\nday: What was the day of the week? We might be interested how macros and total calories varies by day of the week.\ncalories_total: Simulate total daily calorie intake. For this we assume a normal distribution with mean of 3,000 calories and a standard deviation of 250.\nprop_carbs: For each day, what is the proportion of total calories made up from carbohydrates. As this is a proportion, for each day we generate a random number between 0.45 and 0.65.\nprop_protein: For each day, what is the proportion of total calories made up from protein? For each day we generate a random number between 0.15 and 0.20.\nprop_fat: For each day, what is the proportion of total calories made up from fat? As the proportions for each macro-nutrient need to sum to 1, fat is just 1 minus prop_carbs and prop_protein.\n\n\n# simulate the data\nset.seed(123)\n\ndata &lt;- tibble(\n  date = lubridate::ymd(paste(\"2023-04-\", 1:30, sep = \"\")), \n  day = lubridate::wday(date, label = TRUE), \n  calories_total = rnorm(n = 30, mean = 3000, sd = 250), \n  prop_carbs = runif(n = 30, min = 0.45, max = 0.65), \n  prop_protein = runif(n = 30, min = 0.15, max = 0.20), \n  prop_fat = 1 - (prop_carbs + prop_protein)\n  )\ndata\n\n# A tibble: 30 × 6\n   date       day   calories_total prop_carbs prop_protein prop_fat\n   &lt;date&gt;     &lt;ord&gt;          &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 2023-04-01 Sat            2860.      0.583        0.157    0.260\n 2 2023-04-02 Sun            2942.      0.469        0.183    0.348\n 3 2023-04-03 Mon            3390.      0.527        0.167    0.306\n 4 2023-04-04 Tue            3018.      0.505        0.183    0.312\n 5 2023-04-05 Wed            3032.      0.613        0.166    0.221\n 6 2023-04-06 Thu            3429.      0.540        0.159    0.301\n 7 2023-04-07 Fri            3115.      0.612        0.189    0.199\n 8 2023-04-08 Sat            2684.      0.612        0.155    0.233\n 9 2023-04-09 Sun            2828.      0.609        0.173    0.218\n10 2023-04-10 Mon            2889.      0.538        0.176    0.286\n# … with 20 more rows\n\n\nWe can then use these proportions for each macro to calculate how many of the day’s total calories were from carbohydrates, protein, and fats. Once we have this we can remove the proportion columns.\n\ndata &lt;- data %&gt;% \n  mutate(calories_carbs = calories_total * prop_carbs, \n         calories_protein = calories_total * prop_protein, \n         calories_fat = calories_total * prop_fat) %&gt;% \n  select(-starts_with(\"prop_\"))\ndata \n\n# A tibble: 30 × 6\n   date       day   calories_total calories_carbs calories_protein calories_fat\n   &lt;date&gt;     &lt;ord&gt;          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;        &lt;dbl&gt;\n 1 2023-04-01 Sat            2860.          1667.             448.         745.\n 2 2023-04-02 Sun            2942.          1380.             537.        1025.\n 3 2023-04-03 Mon            3390.          1786.             567.        1037.\n 4 2023-04-04 Tue            3018.          1524.             552.         942.\n 5 2023-04-05 Wed            3032.          1859.             503.         670.\n 6 2023-04-06 Thu            3429.          1851.             546.        1032.\n 7 2023-04-07 Fri            3115.          1907.             589.         620.\n 8 2023-04-08 Sat            2684.          1644.             415.         625.\n 9 2023-04-09 Sun            2828.          1722.             490.         616.\n10 2023-04-10 Mon            2889.          1554.             507.         827.\n# … with 20 more rows\n\n\nIn order for us to do visualisations we need to change the calorie data into long format.\n\ndata &lt;- data %&gt;% \n  pivot_longer(calories_total:calories_fat, \n               names_to = \"source\") %&gt;% \n  mutate(source = str_remove(source,\"calories_\"))\ndata\n\n# A tibble: 120 × 4\n   date       day   source  value\n   &lt;date&gt;     &lt;ord&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1 2023-04-01 Sat   total   2860.\n 2 2023-04-01 Sat   carbs   1667.\n 3 2023-04-01 Sat   protein  448.\n 4 2023-04-01 Sat   fat      745.\n 5 2023-04-02 Sun   total   2942.\n 6 2023-04-02 Sun   carbs   1380.\n 7 2023-04-02 Sun   protein  537.\n 8 2023-04-02 Sun   fat     1025.\n 9 2023-04-03 Mon   total   3390.\n10 2023-04-03 Mon   carbs   1786.\n# … with 110 more rows"
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html#different-visualisations",
    "href": "posts/2023-04-01-30DCC-01/index.html#different-visualisations",
    "title": "30-DCC day 1",
    "section": "Different Visualisations",
    "text": "Different Visualisations\n\nBar plot\nAhh the good old humble bar plot. Not really useful for a part-to-whole visualisation (ha! Suddenly I’m a know-it-all on part-to-whole visualisations), but here it is anyway:\n\nbar &lt;- data %&gt;% \n  filter(source != \"total\") %&gt;% \n  ggplot(aes(x = date, y = value, group = source)) + \n  geom_col(aes(fill = source), \n           position = \"dodge\") + \n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL)\nbar\n\n\n\n\n\n\n\n\nNot bad, but it’s hard to differentiate the different days during the month.\n\n\nStacked column plot\nA stacked column plot is similar to the bar plot but the bars are—you guessed it—stacked on top of each other:\n\nstacked_column &lt;- data %&gt;% \n  filter(source != \"total\") %&gt;% \n  ggplot(aes(x = date, y = value)) + \n  geom_col(aes(fill = source)) + \n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL)\nstacked_column\n\n\n\n\n\n\n\n\nThis is clearly better than the bar plot. One useful aspect of this plot is that we get multiple points of information: The height of each column shows the total calories consumed (the whole), and the colours represent the macros that make up that total (the part). It’s very basic, but it’s functional.\n\n\nPolar plot\nI am not sure if this is the correct term for it, but you can wrap the column plot around polar coordinates using coord_polar() in ggplot. This makes it look snazzier, but I am not sure it is more informative.\n\npolar &lt;- data %&gt;% \n  filter(source != \"total\") %&gt;% \n  ggplot(aes(x = date, y = value)) + \n  geom_col(aes(fill = source)) + \n  coord_polar() +\n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL)\npolar\n\n\n\n\n\n\n\n\nIt’s definitely snazzier, and you still retain a feel for the total calories consumed each day. It is harder to ready the y-axis (calories consumed) for each point, and whilst we’re at it the x-axis (date) isn’t that clear either.\nWe also get an idea of the macro contributions to the total, but in the current plot this isn’t completely satisfactory because it’s hard to visualise the category with the smallest proportion (protein). To address this we can reverse the ordering on the geom_col() call using the position argument so that the category with the smallest contribution is on the outer section of each column.\n\npolar_reversed &lt;- data %&gt;% \n  filter(source != \"total\") %&gt;% \n  ggplot(aes(x = date, y = value)) + \n  geom_col(aes(fill = source), \n           position = position_stack(reverse = TRUE)) + \n  coord_polar() +\n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL)\npolar_reversed\n\n\n\n\n\n\n\n\nHere they are all next to each other:\n\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.2.3\n\n(bar + stacked_column) / (polar + polar_reversed)"
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html#grouping-by-day",
    "href": "posts/2023-04-01-30DCC-01/index.html#grouping-by-day",
    "title": "30-DCC day 1",
    "section": "Grouping by day",
    "text": "Grouping by day\nMaybe you want to log how your macros vary on average by day. To do this, we group our data by the day of the week and calculate averages for each day and plot these. We need to briefly go back to wide data to calculate the relevant averages\n\nday_data &lt;- data %&gt;% \n  pivot_wider(names_from = source, values_from = value) %&gt;% \n  group_by(day) %&gt;% \n  summarise(carbs = mean(carbs), \n            protein = mean(protein), \n            fat = mean(fat)) %&gt;% \n  pivot_longer(carbs:fat, names_to = \"source\")\nday_data\n\n# A tibble: 21 × 3\n   day   source  value\n   &lt;ord&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1 Sun   carbs   1575.\n 2 Sun   protein  536.\n 3 Sun   fat      943.\n 4 Mon   carbs   1674.\n 5 Mon   protein  560.\n 6 Mon   fat      821.\n 7 Tue   carbs   1571.\n 8 Tue   protein  532.\n 9 Tue   fat      816.\n10 Wed   carbs   1669.\n# … with 11 more rows\n\n\n\nday_data %&gt;% \n  ggplot(aes(x = day, y = value)) + \n  geom_col(aes(fill = source), \n           position = position_stack(reverse = TRUE)) + \n  coord_polar() +\n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL)"
  },
  {
    "objectID": "posts/2023-04-01-30DCC-01/index.html#grouping-by-month-and-day",
    "href": "posts/2023-04-01-30DCC-01/index.html#grouping-by-month-and-day",
    "title": "30-DCC day 1",
    "section": "Grouping by month and day",
    "text": "Grouping by month and day\nSo you’re really keen and you’ve logged your calorie intake daily throughout all of 2023. Let’s calculaute the average for each day of the week, and see how these totals change across the months of the year.\nFirst let’s simulate some data for the entire year. This is similar to earlier, but we first need to create a date column that spans the whole year.\n\n# create a data frame with all the days of the year\nyear_data &lt;- tibble(year = 2023) %&gt;% \n  mutate(date = list(seq(lubridate::ymd(paste0(year, \"-01-01\")), \n                         lubridate::ymd(paste0(year, \"-12-31\")), \n                         by = \"day\"))) %&gt;% \n  unnest(date) %&gt;% \n  select(-year) \n\n# simulate calorie data\nset.seed(234)\nyear_data &lt;- year_data %&gt;% \n  mutate(day = lubridate::wday(date, label = TRUE), \n         month = lubridate::month(date, label = TRUE), \n         calories_total = rnorm(n = 365, mean = 3000, sd = 250), \n         prop_carbs = runif(n = 365, min = 0.45, max = 0.65), \n         prop_protein = runif(n = 365, min = 0.15, max = 0.20), \n         prop_fat = 1 - (prop_carbs + prop_protein)) %&gt;% \n  mutate(calories_carbs = calories_total * prop_carbs, \n         calories_protein = calories_total * prop_protein, \n         calories_fat = calories_total * prop_fat) %&gt;% \n  select(-starts_with(\"prop_\")) %&gt;% \n  pivot_longer(calories_total:calories_fat, \n               names_to = \"source\") %&gt;% \n  mutate(source = str_remove(source,\"calories_\"))\n\nNow we have this let’s follow previous steps and view a stacked column plot, faceting by month.\n\nyear_data %&gt;% \n  filter(source != \"total\") %&gt;% \n  group_by(day, month, source) %&gt;% \n  summarise(mean_value = mean(value)) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(x = day, y = mean_value)) + \n  geom_col(aes(fill = source), \n           position = position_stack(reverse = TRUE)) + \n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL) + \n  facet_wrap(~month)\n\n\n\n\n\n\n\n\nA slight tweak is needed to the x-axis labels to make them more readable:\n\nyear_data %&gt;% \n  filter(source != \"total\") %&gt;% \n  group_by(day, month, source) %&gt;% \n  summarise(mean_value = mean(value)) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(x = day, y = mean_value)) + \n  geom_col(aes(fill = source), \n           position = position_stack(reverse = TRUE)) + \n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL) + \n  theme(axis.text.x = element_text(angle = 90)) +\n  facet_wrap(~month)\n\n\n\n\n\n\n\n\nAnd the polar plot equivalent:\n\nyear_data %&gt;% \n  filter(source != \"total\") %&gt;% \n  group_by(day, month, source) %&gt;% \n  summarise(mean_value = mean(value)) %&gt;% \n  ungroup() %&gt;% \n  ggplot(aes(x = day, y = mean_value)) + \n  geom_col(aes(fill = source), \n           position = position_stack(reverse = TRUE)) + \n  coord_polar() +\n  labs(x = NULL, \n       y =\"Calories Consumed\", \n       fill = NULL) + \n  facet_wrap(~month)"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Recent Blog Posts",
    "section": "",
    "text": "What’s the best notebook\n\n\n\ncoding\n\n\nneovim\n\n\nquarto\n\n\n\nWhy I started this blog?\n\n\n\n\n\n\nMar 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\ntest\n\n\n\nR\n\n\ntest\n\n\n\ntest\n\n\n\n\n\n\nMar 4, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-03-04/index.html",
    "href": "posts/2024-03-04/index.html",
    "title": "test",
    "section": "",
    "text": "test\n\nimport os\n\nprint(os.name)\n\nposix"
  },
  {
    "objectID": "posts/2024-03-08/index.html",
    "href": "posts/2024-03-08/index.html",
    "title": "What’s the best notebook",
    "section": "",
    "text": "What are quarto documents and jupyter notebooks?\nQuarto documents are a way to preview raw html of jupyter notebooks. But so much more.\nJupyter notebooks (I used for quite some time) are a way to have in-line code, split into cells that can be rendered one cell at a time. Typically jupyter notebooks are used with python and some text written in markdown. Despite this I find jupyter notebooks and its sister program jupyter labs to be great if you want to get started and learn python. Beyond this, jupyter lab offers a useful gui that aids almost any data scientist (or anyone who wishes to write python code for that matter) to process data in a more interactive way than just writing python code in the terminal. For example:\n\n\n\n\n\nHere I show my first (slightly laughable) attempt at importing matplotlib. Of course, on my windows machine I didn’t have it. So I thought this was a great example of how terminal based coding really goes like.\nThere is not much to see only really the raw code entered line-by-line. Whereas in a jupyter notebook that line plot can be created much more easily, with in-built syntax highlighting and code suggestions, it means that your less likely to find yourself in a situation as I found myself in above. (where you really don’t have a library or package installed before trying to import it!)\n\n\n\n\n\nHere above I show that those 6 or so lines can be executed in a ‘cell’ whereby the whole block of code can be run instead of typing the code line by line.\nThe above is great and it just works. I’m not going to bash jupyter lab or jupyter notebooks, you can find many videos online of people doing that; it’s also true and likely that I will still use them.\nBut I feel I have a workflow that works better and works well especially for me. If you’re like me and want to customise a coding editor to make it what your use case is, then keep reading.\n\n\nNeovim and the configuration\nPerhaps I started this whole rabbit-hole journey around 4th October 2023 with the first commit: 97ca162 But since then my whole configuration has altered and changed many times and in that process I have moved away from jupyter notebooks to quarto documents. Quarto documents I found much much easier to be able to do inline coding of any language by just specifying the tag I need ‘r’,‘python’,‘bash’,‘html’. I have also moved away from editing quarto documents in Rstudio and now solely edit files using neovim which looks like this:\n\nMy configuration allows for multiple things. So now everything I do, I do in neovim.\nSo why I chose quarto over jupyter notebooks, probably isn’t too clear at this point. However, the neovim configuration I have set up allows for all the things that can be offered from all text editors like vscode, Rstudio, jupyter notebooks but without a gui getting in the way and full customisability. There truly are a myriad of benefits (the biggest one if the keybindings, movements and gestures that let you edit and write code very fast) and I wish anyone who would like something that they can call their “own” to go and explore neovim.\nAlthough the customisability took several months (this is probably the only downside, it is a lot of tinkering), I feel it is worth it and along the way all this tinkering has helped me to begin to learn more about coding languages such as lua, python and JavaScript and shell scripting languages.\n\n\nThe purpose of this blog\nThe purpose of this blog is to really document these things. The things that have led me to the point I’m at right now. To start to write down coding notes about this particular configuration journey.\nI’d also like to dabble a bit of coding regarding data analysis in R and Python and to the mix too. And also to document data analysis of fMRI data. I think this would be the perfect place to do this.\n\n\nSuggestions?\nIf you have any suggestions how I can make this useful to you or would like to reach out to me please feel free to do so. I hope this blog will inform others’, if at least inform myself 😂."
  }
]